{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Selection Strategies in a Pool-Based Setting\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add Parzen Window Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "\n",
    "class PWC(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, n_classes, metric='rbf', n_neighbours=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Parzen Window Classifier (PWC) is a simple and probabilistic classifier. This classifier is based on a\n",
    "        non-parametric density estimation obtained by applying a kernel function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_classes: int,\n",
    "            This parameters indicates the number of available classes.\n",
    "        metric: str,\n",
    "            The metric must a be a valid kernel defined by the function sklearn.metrics.pairwise.pairwise_kernels.\n",
    "        n_neighbours: int,\n",
    "            Number of nearest neighbours. Default is None, which means all available samples are considered.\n",
    "        kwargs: str,\n",
    "            Any further parameters are passed directly to the kernel function.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        n_classes: int,\n",
    "            This parameters indicates the number of available classes.\n",
    "        metric: str,\n",
    "            The metric must a be a valid kernel defined by the function sklearn.metrics.pairwise.pairwise_kernels.\n",
    "        n_neighbours: int,\n",
    "            Number of nearest neighbours. Default is None, which means all available samples are considered.\n",
    "        kwargs: str,\n",
    "            Any further parameters are passed directly to the kernel function.\n",
    "        X: array-like, shape = [n_samples, n_features]\n",
    "            The sample matrix X is the feature matrix representing the samples.\n",
    "        y: array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
    "            It contains the class labels of the training samples.\n",
    "            The number of class labels may be variable for the samples.\n",
    "        Z: array-like, [n_samples, n_classes]\n",
    "            The class labels are represented by counting vectors. An entry Z[i,j] indicates how many class labels of class j\n",
    "            were provided for training sample i.\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        O. Chapelle, \"Active Learning for Parzen Window Classifier\",\n",
    "        Proc. Tenth Int'l Workshop Artificial Intelligence and Statistics, 2005.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.metric = metric\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.kwargs = kwargs\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.Z = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model using X as training data and y as class labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: matrix-like, shape = [n_samples, n_features]\n",
    "            The sample matrix X is the feature matrix representing the samples.\n",
    "        y: array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
    "            It contains the class labels of the training samples.\n",
    "            The number of class labels may be variable for the samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: PWC,\n",
    "            The PWC is fitted to the training data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        if np.size(X, 0) == 0:\n",
    "            return self\n",
    "\n",
    "        # convert labels to count vectors\n",
    "        self.Z = np.zeros((np.size(X, 0), self.n_classes))\n",
    "        for i in range(np.size(self.Z, 0)):\n",
    "            self.Z[i, y[i]] += 1\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Return probability estimates for the test data X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X:  array-like, shape = [n_samples, n_features] or shape = [n_samples, m_samples] if metric == 'precomputed'\n",
    "            Test samples.\n",
    "        C: array-like, shape = [n_classes, n_classes]\n",
    "            Classification cost matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        P:  array-like, shape = [t_samples, n_classes]\n",
    "            The class probabilities of the input samples. Classes are ordered by lexicographic order.\n",
    "        \"\"\"\n",
    "\n",
    "        # no training data -> random prediction\n",
    "        if np.size(X, 0) == 0:\n",
    "            return np.full((np.size(X, 0), self.n_classes), 1. / self.n_classes)\n",
    "\n",
    "        # if normalize is false, the probabilities are frequency estimates\n",
    "        normalize = kwargs.pop('normalize', True)\n",
    "\n",
    "        # calculating metric matrix\n",
    "        K = pairwise_kernels(X, self.X, metric=self.metric, **self.kwargs)\n",
    "\n",
    "        if self.n_neighbours is None:\n",
    "            # calculating labeling frequency estimates\n",
    "            P = K @ self.Z\n",
    "        else:\n",
    "            if np.size(self.X, 0) < self.n_neighbours:\n",
    "                n_neighbours = np.size(self.X, 0)\n",
    "            else:\n",
    "                n_neighbours = self.n_neighbours\n",
    "            indices = np.argpartition(K, -n_neighbours, axis=1)[:, -n_neighbours:]\n",
    "            P = np.empty((np.size(X, 0), self.n_classes))\n",
    "            for i in range(np.size(X, 0)):\n",
    "                P[i, :] = K[i, indices[i]] @ self.Z[indices[i], :]\n",
    "\n",
    "        if normalize:\n",
    "            # normalizing probabilities of each sample\n",
    "            normalizer = np.sum(P, axis=1)\n",
    "            P[normalizer > 0] /= normalizer[normalizer > 0, np.newaxis]\n",
    "            P[normalizer == 0, :] = [1 / self.n_classes] * self.n_classes\n",
    "            # normalizer[normalizer == 0.0] = 1.0\n",
    "            # for y_idx in range(self.n_classes):\n",
    "            #     P[:, y_idx] /= normalizer\n",
    "\n",
    "        return P\n",
    "\n",
    "    def predict(self, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Return class label predictions for the test data X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X:  array-like, shape = [n_samples, n_features] or shape = [n_samples, m_samples] if metric == 'precomputed'\n",
    "            Test samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y:  array-like, shape = [n_samples]\n",
    "            Predicted class labels class.\n",
    "        \"\"\"\n",
    "        C = kwargs.pop('C', None)\n",
    "\n",
    "        if C is None:\n",
    "            C = np.ones((self.n_classes, self.n_classes))\n",
    "            np.fill_diagonal(C, 0)\n",
    "\n",
    "        P = self.predict_proba(X, normalize=True)\n",
    "        return np.argmin(np.dot(P, C), axis=1)\n",
    "\n",
    "\n",
    "def largest_indices(array, n):\n",
    "    \"\"\"\n",
    "    Returns the n largest indices from a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array: array-like\n",
    "        Array of values.\n",
    "    n: int\n",
    "        Number of the searched maximal values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    indices: array-like, shape = [n]\n",
    "        Indices of the n maximal values of the array.\n",
    "    \"\"\"\n",
    "    flat = array.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\"\"\"Create Dataset.\"\"\"\n",
    "X, y = make_blobs(300, centers=2, cluster_std=2.3, random_state=RANDOM_SEED)\n",
    "new_center = max(X, key=lambda x: x[1])\n",
    "size = 100\n",
    "X1, y1 = np.c_[np.random.normal(loc=new_center[0], size=size),\n",
    "               np.random.normal(loc=new_center[1], size=size)], np.ones(size)\n",
    "X, y = np.r_[X, X1], np.r_[y, y1].astype(int)\n",
    "\n",
    "\n",
    "## Plot dataset method\n",
    "def plot_dataset(x):\n",
    "    plt.plot(x[:, 0], x[:, 1], '.')\n",
    "\n",
    "\n",
    "def plot_dataset_with_class(x, y):\n",
    "    uniques = np.unique(y)\n",
    "    [plt.plot(x[:, 0][y == unique], x[:, 1][y == unique], '.') for unique in uniques]\n",
    "\n",
    "plt.figure()\n",
    "plot_dataset(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize sampling and decision boundary\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, X, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    X0, X1 = X[:, 0], X[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool-base Active Learning\n",
    "___\n",
    "Describe the different steps in a general pool-based active learning\n",
    "scenario and find each step in the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot sampling\n",
    "def plot_sampling(X, y, clf, selection_strategy, num_queries=5, time_between_sampling=0.5, ax=None):\n",
    "    \"\"\"\n",
    "    Visualization of the sampling with the decision boundary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array_like\n",
    "        Numpy array with samples as rows and features as columns.\n",
    "    y: array_like\n",
    "        Corresponding labels of the samples.\n",
    "    clf: sklearn classifier\n",
    "        Classifier that will be used in the AL process.\n",
    "    selection_strategy: function\n",
    "        Method that queries a sample and return an index.\n",
    "    num_queries: int\n",
    "        Number of AL queries.\n",
    "    \"\"\"\n",
    "    # Define labeled and unlabeled pool\n",
    "    X_unlabeled, y_unlabeled = X, y \n",
    "    X_labeled, y_labeled = list(), list()\n",
    "    \n",
    "    if ax:\n",
    "        ax.cla()\n",
    "        countour = None\n",
    "        plot_dataset_with_class(X, y)\n",
    "\n",
    "    for step in range(num_queries):\n",
    "        \n",
    "        num_classes = len(np.unique(y_labeled))\n",
    "        \n",
    "        if num_classes < 2:\n",
    "            query_idx = random_sampling(X_unlabeled)\n",
    "            query_sample, query_label = X_unlabeled[query_idx], y_unlabeled[query_idx]\n",
    "            \n",
    "            X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)\n",
    "            y_unlabeled = np.delete(y_unlabeled, query_idx, axis=0)\n",
    "            \n",
    "            X_labeled.append(query_sample)\n",
    "            y_labeled.append(query_label)\n",
    "            \n",
    "            if ax:\n",
    "                ax.plot(query_sample[0], query_sample[1], 'oy', markeredgewidth=1, \n",
    "                        markeredgecolor=(0, 0, 0, 1), markersize=8)\n",
    "                \n",
    "        else:\n",
    "            clf.fit(np.array(X_labeled), np.array(y_labeled).astype(int))\n",
    "            \n",
    "                \n",
    "            if selection_strategy.__name__ == 'random_sampling':\n",
    "                query_idx = selection_strategy(X_unlabeled)\n",
    "            elif selection_strategy.__name__ == 'uncertainty_sampling':\n",
    "                query_idx = selection_strategy(X_unlabeled, clf)\n",
    "            elif selection_strategy.__name__ == 'ensemble_based_sampling':\n",
    "                query_idx = selection_strategy(X_unlabeled, X_labeled, y_labeled)\n",
    "            elif selection_strategy.__name__ == 'expected_error_reduction':\n",
    "                query_idx = selection_strategy(X_unlabeled, X_labeled, y_labeled, clf)\n",
    "\n",
    "            # Implement your own strategies here! \n",
    "\n",
    "            query_sample, query_label = X_unlabeled[query_idx], y_unlabeled[query_idx]\n",
    "            \n",
    "            X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)\n",
    "            y_unlabeled = np.delete(y_unlabeled, query_idx, axis=0)\n",
    "            \n",
    "            X_labeled.append(query_sample)\n",
    "            y_labeled.append(query_label)\n",
    "\n",
    "            if ax: \n",
    "                clf.fit(np.array(X_labeled), np.array(y_labeled).astype(int))\n",
    "                # plot decision boundary\n",
    "                if countour is not None:\n",
    "                    for coll in countour.collections:\n",
    "                        coll.remove()\n",
    "                        \n",
    "                countour = plot_contours(plt.gca(), clf, X, alpha=0.5, cmap=plt.cm.coolwarm)\n",
    "\n",
    "                ax.plot(query_sample[0], query_sample[1], 'oy', markeredgewidth=1,\n",
    "                        markeredgecolor=(0, 0, 0, 1), markersize=8)\n",
    "\n",
    "        if ax: \n",
    "            plt.gcf().canvas.draw()\n",
    "            plt.pause(time_between_sampling)\n",
    "    \n",
    "def random_sampling(pool):\n",
    "    \"\"\"Randomly selects an instances.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array_like\n",
    "        Array of all unlabeled instances.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    index: int\n",
    "        Random index of all instances.\n",
    "    \"\"\"\n",
    "    return np.random.randint(len(pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code and watch the figure above\n",
    "clf = PWC(n_classes=2, gamma=1)\n",
    "plot_sampling(X, y, clf, random_sampling, num_queries=10, time_between_sampling=.5, ax=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Strategies:\n",
    "___\n",
    "- Uncertainty Sampling,\n",
    "- Ensemble-based Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_sampling(X_unlabeled, clf):\n",
    "    \"\"\"Queries the instance the model is least certain about.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_unlabeled: ndarray\n",
    "       Array of all unlabeled instances.\n",
    "    clf: sklearn classifier\n",
    "        The current model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    index: int\n",
    "        Index of the instance that the model is least certain about.\n",
    "    \"\"\"\n",
    "    # binary problem assumed\n",
    "    probas = clf.predict_proba(X_unlabeled)\n",
    "    score = np.max(probas, axis=1)\n",
    "    idx = np.argmin(score)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble-based Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_based_sampling(X_unlabeled, X_labeled, y_labeled, \n",
    "                            models=[SVC(),\n",
    "                                    GaussianNB(), \n",
    "                                    DecisionTreeClassifier(),\n",
    "                                    RandomForestClassifier(),\n",
    "                                    AdaBoostClassifier()]):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_unlabeled: ndarray\n",
    "       Array of all unlabeled instances.\n",
    "    X_labeled: list\n",
    "        Array of all labeled instances.\n",
    "    y_labeled: list\n",
    "        Array of all labels.\n",
    "    clfs: list\n",
    "        List of sklearn models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    index: int\n",
    "        Index of the instance that minimizes the generalization error.\n",
    "    \"\"\"\n",
    "    # Create and Train all models\n",
    "    for model in models:\n",
    "        model.fit(np.array(X_labeled), np.array(y_labeled).astype(int))\n",
    "    \n",
    "    # Let the trained models vote for unlabeled data\n",
    "    votes = np.zeros((len(X_unlabeled), len(models)))\n",
    "    for i, model in enumerate(models):\n",
    "        votes[:, i] = model.predict(X_unlabeled)\n",
    "    \n",
    "    # Compute vote disagreement\n",
    "    vote_entropy = []\n",
    "    for vote in votes:\n",
    "        vote_entropy.append(0.0)\n",
    "        label_count = {}\n",
    "        for label in vote:\n",
    "            label_count[label] = label_count.setdefault(label, 0) + 1\n",
    "        # Using vote entropy to measure disagreement\n",
    "        for label in label_count.keys():\n",
    "            vote_entropy[-1] -= label_count[label] / len(models) * \\\n",
    "                np.log(float(label_count[label]) / len(models))\n",
    "\n",
    "    idx = np.random.choice(np.where(np.isclose(vote_entropy, np.max(vote_entropy)))[0])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Sampling\n",
    "- Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code and watch the figure above\n",
    "clf = PWC(n_classes=2, gamma=1)\n",
    "plot_sampling(X, y, clf, uncertainty_sampling, num_queries=10, time_between_sampling=.5, ax=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble-based Sampling\n",
    "- Decision boundary\n",
    "- Reliability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code and watch the figure above\n",
    "clf = PWC(n_classes=2, gamma=1)\n",
    "plot_sampling(X, y, clf, ensemble_based_sampling, num_queries=10, time_between_sampling=0.5, ax=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from parzen_window_classifier import PWC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.special import gamma\n",
    "from sklearn.neighbors.kde import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OPAL strategy\n",
    "\n",
    "\"Optimized Probabilistic Active Learning\" ([Krempl, Kottke, Lemaire in Machine Learning 2015](https://link.springer.com/article/10.1007/s10994-015-5504-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def comb(m, k):\n",
    "    return gamma(m+1) / (gamma(k+1) * gamma(m-k+1))\n",
    "\n",
    "def I(n, p, tau, m, k):\n",
    "    constraint = ((n*p)+k) / ((n+m)+1e-19)\n",
    "    if constraint < tau:\n",
    "        equ = (1-tau)        * gamma(1-k+m+n- n*p) * gamma(2+k+ n*p) / gamma(3+m+n)\n",
    "    elif constraint == tau: \n",
    "        equ = (tau - tau**2) * gamma(1-k+m+n- n*p) * gamma(1+k+ n*p) / gamma(2+m+n)\n",
    "    elif constraint > tau:\n",
    "        equ = tau            * gamma(2-k+m+n- n*p) * gamma(1+k+ n*p) / gamma(3+m+n)\n",
    "    return comb(m, k) * equ\n",
    "\n",
    "## Vectorized form\n",
    "def I_arr(n, p, tau, m, k):\n",
    "    \n",
    "    constraints = np.zeros(len(n)) + tau\n",
    "    constraints[n+m != 0] = ((n[n+m != 0] * p[n+m != 0])+k) / ((n[n+m != 0]+m))\n",
    "        \n",
    "    gains = np.zeros(len(n))\n",
    "    \n",
    "    smaller = constraints < tau\n",
    "    gains[smaller] = ((1-tau) * ((gamma(1 - k + m + n[smaller] - (n[smaller]*p[smaller])) * \n",
    "                           gamma(2 + k + (n[smaller]*p[smaller]))) / gamma(3 + m + n[smaller])))\n",
    "    \n",
    "    equal = constraints == tau\n",
    "    gains[equal] = (tau - tau**2) * ((gamma(1 - k + m + n[equal] - (n[equal]*p[equal])) * \n",
    "                                      gamma(1 + k + (n[equal]*p[equal]))) / gamma(2 + m + n[equal]))\n",
    "    \n",
    "    bigger = constraints > tau\n",
    "    gains[bigger] = tau * ((gamma(2 - k + m + n[bigger] -(n[bigger]*p[bigger])) * \n",
    "                            gamma(1 + k + (n[bigger]*p[bigger]))) / gamma(3 + m + n[bigger]))\n",
    "    return comb(m, k) * gains\n",
    "\n",
    "\n",
    "def probabilistic_gain(n, p, tau, m):\n",
    "    first_factor = ((n+1)/m) * comb(n, n*p) \n",
    "    if type(n) == np.ndarray:\n",
    "        return  first_factor * (I_arr(n, p, tau, 0, 0) - np.sum([I_arr(n, p, tau, m, k) for k in range(m+1)],axis=0))\n",
    "    else:\n",
    "        return first_factor * (I(n, p, tau, 0, 0) - np.sum([I(n, p, tau, m, k) for k in range(m+1)]))\n",
    "    \n",
    "def probabilistic_active_learning(X_unlabeled, X_labeled, y_labeled, clf, tau=.5, m_max=2,bw=2):\n",
    "    # compute density\n",
    "    densities = np.exp(KernelDensity(bw).fit(np.r_[X_unlabeled, X_labeled]).score_samples(X_unlabeled))\n",
    "    n = np.max(clf.predict_proba(X_unlabeled, normalize=False), axis=1)\n",
    "    p = clf.predict_proba(X_unlabeled)[:,1]\n",
    "    dweighted_pgain = probabilistic_gain(n, p, tau, m_max) * densities\n",
    "        \n",
    "    return np.argmax(dweighted_pgain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.show()\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code and watch the figure above\n",
    "clf = PWC(n_classes=2, gamma=.05)\n",
    "plot_sampling(X, y, clf, probabilistic_active_learning, num_queries=20, time_between_sampling=.5, ax=plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "___\n",
    "Which of the previous methods seems to work best and why? How could\n",
    "this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(500,centers=5, random_state=42)\n",
    "y = y % 2\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=y, marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"5 times 3 Fold Cross-Validation with 30 queries\"\"\"\n",
    "## Define Parameters\n",
    "strats = {'Random_Sampling':random_sampling,\n",
    "          'Uncertainty_Sampling':uncertainty_sampling,\n",
    "          'Ensemble-Based_Sampling':ensemble_based_sampling,\n",
    "          'Probabilistic_Active_Learning':probabilistic_active_learning,}\n",
    "reps = 5\n",
    "folds = 3\n",
    "num_queries = 45\n",
    "num_classes = 2\n",
    "scores = np.zeros((reps, len(strats), folds, num_queries))\n",
    "random_state = 42\n",
    "pwc_gamma = 0.05\n",
    "cross_validation = KFold(n_splits=folds, random_state=random_state)\n",
    "\n",
    "## Start cv\n",
    "for irep in range(reps):\n",
    "    print(irep)\n",
    "    for ifold, (train_idx, test_idx) in enumerate(cross_validation.split(X)):\n",
    "        # Get train and test set and define classifier\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_test, y_test = X[test_idx], y[test_idx]\n",
    "        clf_start = PWC(n_classes=num_classes, gamma=pwc_gamma)\n",
    "\n",
    "        # Create labeled and unlabeled pool\n",
    "        X_unlabeled_start, y_unlabeled_start = X_train, y_train\n",
    "        X_labeled_start, y_labeled_start = list(), list()\n",
    "\n",
    "        # Random sampling until all classes are found \n",
    "        while len(np.unique(y_labeled_start)) < num_classes:\n",
    "            query_idx = random_sampling(X_unlabeled_start)\n",
    "            query_sample, query_label = X_unlabeled_start[query_idx], y_unlabeled_start[query_idx]\n",
    "\n",
    "            X_unlabeled_start = np.delete(X_unlabeled_start, query_idx, axis=0)\n",
    "            y_unlabeled_strat = np.delete(y_unlabeled_start, query_idx, axis=0)\n",
    "\n",
    "            X_labeled_start.append(query_sample)\n",
    "            y_labeled_start.append(query_label)\n",
    "\n",
    "        # Fit classifier with randomly filled set\n",
    "        clf_start.fit(np.array(X_labeled_start), np.array(y_labeled_start,dtype=int))\n",
    "\n",
    "        # Iterate over all selection strategies\n",
    "        for istrat, selection_strategy_name in enumerate(strats):\n",
    "            # Get a copy of labeled, unlabeled start set and the classifier \n",
    "            X_unlabeled, y_unlabeled = X_unlabeled_start.copy(), y_unlabeled_start.copy()\n",
    "            X_labeled, y_labeled = X_labeled_start.copy(), y_labeled_start.copy()\n",
    "            clf = copy.deepcopy(clf_start)\n",
    "\n",
    "            # Make queries for the specific srategie and train clf, get score at the end\n",
    "            for iquery in range(num_queries):\n",
    "                selection_strategy = strats[selection_strategy_name]\n",
    "\n",
    "                if selection_strategy.__name__ == 'random_sampling':\n",
    "                    query_idx = selection_strategy(X_unlabeled)\n",
    "                elif selection_strategy.__name__ == 'uncertainty_sampling':\n",
    "                    query_idx = selection_strategy(X_unlabeled, clf)\n",
    "                elif selection_strategy.__name__ == 'ensemble_based_sampling':\n",
    "                    query_idx = selection_strategy(X_unlabeled, X_labeled, y_labeled)\n",
    "                elif selection_strategy.__name__ == 'expected_error_reduction':\n",
    "                    query_idx = selection_strategy(X_unlabeled, X_labeled, y_labeled, clf)\n",
    "                elif selection_strategy.__name__ == 'probabilistic_active_learning':\n",
    "                    query_idx = selection_strategy(X_unlabeled, X_labeled, y_labeled, clf)\n",
    "\n",
    "                query_sample, query_label = X_unlabeled[query_idx], y_unlabeled[query_idx]\n",
    "\n",
    "                X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)\n",
    "                y_unlabeled = np.delete(y_unlabeled, query_idx, axis=0)\n",
    "\n",
    "                X_labeled.append(query_sample)\n",
    "                y_labeled.append(query_label)\n",
    "                clf.fit(X_labeled, y_labeled)\n",
    "                scores[irep, istrat, ifold, iquery] = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Comparison')\n",
    "\n",
    "for cv_scores, strat_name in zip(np.mean(scores, axis=2), strats):\n",
    "    means = np.mean(cv_scores, 0)\n",
    "    std_err = np.std(cv_scores, 0) / np.sqrt(folds)\n",
    "    x_axis = range(1, len(means)+1)\n",
    "    \n",
    "    plt.plot(x_axis, means, label=strat_name)\n",
    "    plt.fill_between(x_axis, means-std_err, means+std_err, alpha=0.2)\n",
    "plt.xlabel('acquired samples')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
